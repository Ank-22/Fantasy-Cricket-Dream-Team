{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batsman_train = pd.read_csv('Bat_Trainset.csv', header = 0)\n",
    "Bowler_train = pd.read_csv('Bowl_Trainset.csv', header = 0)\n",
    "\n",
    "\n",
    "Bowler_train['Opp_SR'].replace([np.inf,-np.inf],np.nan)\n",
    "Bowler_train['Opp_avg'].replace([np.inf,-np.inf],np.nan)\n",
    "Bowler_train['Ven_SR'].replace([np.inf,-np.inf],np.nan)\n",
    "Bowler_train['Ven_avg'].replace([np.inf,-np.inf],np.nan)\n",
    "\n",
    "\n",
    "\n",
    "Bowler_train['Opp_SR'].fillna(0, inplace = True)\n",
    "Bowler_train['Opp_avg'].fillna(0, inplace = True)\n",
    "Bowler_train['Ven_SR'].fillna(0, inplace = True)\n",
    "Bowler_train['Ven_avg'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: -915.01 (431.87) MSE\n"
     ]
    }
   ],
   "source": [
    "x = Batsman_train.iloc[:,3:-1]\n",
    "y = Batsman_train.iloc[:,-1]\n",
    "x\n",
    "y\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state=42, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, input_dim=30, kernel_initializer = 'normal', activation='relu'))\n",
    "    model.add(Dense(50, input_dim=50, kernel_initializer = 'normal', activation='relu'))\n",
    "    model.add(Dense(9, input_dim=30, kernel_initializer = 'normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    #print(model)\n",
    "    return model\n",
    "\n",
    "MODEL = baseline_model\n",
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=MODEL, epochs=40, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=12)\n",
    "results = cross_val_score(estimator, x, y, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batsman.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib \n",
    "  \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(MODEL, 'Batsman.pkl') \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: -989.32 (652.07) MSE\n"
     ]
    }
   ],
   "source": [
    "X = Bowler_train.iloc[:,3:-1]\n",
    "Y = Bowler_train.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "# define Bowler base model\n",
    "def bowler_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, input_dim=30, kernel_initializer = 'normal', activation='relu'))\n",
    "    model.add(Dense(30, input_dim=30, kernel_initializer = 'normal', activation='relu'))\n",
    "    model.add(Dense(9, input_dim=9, kernel_initializer = 'normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    #print(model)\n",
    "    return model\n",
    "\n",
    "BOWLER_MODEL = baseline_model\n",
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=BOWLER_MODEL, epochs=40, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=12)\n",
    "results = cross_val_score(estimator, x, y, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9af414e5182d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Use the loaded model to make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel_for_Bowler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.externals import joblib \n",
    "  \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(BOWLER_MODEL, 'Bowler.pkl') \n",
    "  \n",
    "# Load the model from the file \n",
    "model_for_Bowler = joblib.load('Bowler.pkl')  \n",
    "  \n",
    "# Use the loaded model to make predictions \n",
    "model_for_Bowler.predict(X_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Tot_runs    Tot_SR    Tot_avg  Opp_runs    Opp_SR    Opp_avg  Ven_runs  \\\n",
      "809       3824  0.915051  40.680851       598  0.991708  35.176471        52   \n",
      "707        115  0.777027   4.423077        24  0.774194   4.800000         3   \n",
      "1062        77  0.583333   4.052632        17  0.850000   5.666667         0   \n",
      "660       1242  0.930337  28.227273         4  0.222222   2.000000        40   \n",
      "976         57  1.036364   8.142857         1  0.500000   1.000000         2   \n",
      "...        ...       ...        ...       ...       ...        ...       ...   \n",
      "121         10  0.909091  10.000000        10  0.909091  10.000000        10   \n",
      "1044        37  0.973684  37.000000        37  0.973684  37.000000        37   \n",
      "1095        41  0.694915   8.200000        16  0.842105   8.000000         6   \n",
      "860       1239  0.923937  35.400000       401  0.934732  44.555556       126   \n",
      "1126         7  0.333333   7.000000         7  0.333333   7.000000         7   \n",
      "\n",
      "        Ven_SR  Ven_avg  \n",
      "809   1.019608     52.0  \n",
      "707   0.500000      3.0  \n",
      "1062  0.000000      0.0  \n",
      "660   1.081081     10.0  \n",
      "976   0.666667      1.0  \n",
      "...        ...      ...  \n",
      "121   0.909091     10.0  \n",
      "1044  0.973684     37.0  \n",
      "1095  0.600000      6.0  \n",
      "860   1.000000     63.0  \n",
      "1126  0.333333      7.0  \n",
      "\n",
      "[904 rows x 9 columns]\n",
      "809     101\n",
      "707      50\n",
      "1062      0\n",
      "660       0\n",
      "976      50\n",
      "       ... \n",
      "121      90\n",
      "1044     97\n",
      "1095     60\n",
      "860     102\n",
      "1126     33\n",
      "Name: Performance, Length: 904, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x = Batsman_train.iloc[:,3:-1]\n",
    "y = Batsman_train.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state=42, shuffle=True)\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "\t  'learning_rate': 0.01, 'loss': 'ls'}\n",
    "\n",
    "model = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 sq:  0.8872557395404411\n",
      "Mean squared error: 533.15\n",
      "Test Variance score: 0.79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.66029461  73.97450094  10.22455205  11.28033717  48.59512415\n",
      " 110.96729209  79.51785141  23.598708     1.43645302 129.9359826\n",
      "   1.66029461  53.28261469  49.68422724  77.12588383  54.384409\n",
      " 123.4685333  120.40352596  87.83033422  74.20289449 119.93989975\n",
      "  73.50537303  33.03206119  66.78478654   2.36443045 122.65586521\n",
      "  84.8351074   81.72833624  11.71646312  73.93172947  74.79305131\n",
      "  54.49022013  46.53273707  73.67782915  33.24130499 125.1875718\n",
      "   1.66029461  62.41893644  52.83459777  17.46819796  52.25182571\n",
      "  33.97458183  70.12812508  23.91629338  78.49477578  24.17737575\n",
      "  35.50465282 114.61800387  80.00193898  31.71315488  73.00400537\n",
      " 105.85795996 124.49565913  22.60269528  82.14245716  56.3288802\n",
      "  53.97685126 108.98708327 103.63926782  48.30513158   1.66029461\n",
      " 122.52143101 260.17343373  45.97004336 255.76380377  23.43506201\n",
      "  42.48777661   1.66029461  87.02628789   1.5820704  116.79402309\n",
      "  14.82800263  80.04137508  79.62597034  36.91609565  28.55835027\n",
      "  47.49122407  69.89996743  72.96632708  82.90684265  54.17343451\n",
      "  67.05363538  82.97346082  53.36831865  36.6350148   81.27287508\n",
      " 100.39632131  33.22287035  53.92309526  51.50673252  18.40550654\n",
      " 259.20528222   1.43645302  76.25284411  70.57203132 101.00324337\n",
      "  33.69570171  77.48578006  53.3580952   69.20315386  21.82834991\n",
      "  75.10540511  33.09683538  72.809179     1.66029461  16.53413459\n",
      "  86.04662986  85.45205128 201.55482038  58.47127949   2.71272935\n",
      " 119.55633779 105.51624873  69.01265465  43.26385287  64.21151196\n",
      "  52.56195541  78.12137074   1.4103648    1.43645302  31.25575018\n",
      " 145.45919059  57.67321228 139.35396503   3.66281997  79.10656981\n",
      "  54.81584043 132.80558612  77.13616574  75.57774341   1.43645302\n",
      "  24.00136007  46.20349707  53.5624265   55.56167306  79.16704829\n",
      "  28.12327042  82.39963843  70.69998076 133.27945318  19.1964823\n",
      "  81.54138003  68.8305558   72.52695377  48.54255916   1.66029461\n",
      "  69.23446345  64.09134965  52.02241356  64.48929632  21.0281477\n",
      "  54.82805353  22.5970286   92.64671291  55.96625017  74.26013861\n",
      "   7.79857057  57.30010709   2.89876293  77.6607027   66.67114801\n",
      "  96.12892936  81.11367713  68.6070132   18.14281468  72.80765462\n",
      " 117.14874596  48.66048008   2.79093557  26.74838369  33.58702228\n",
      "  41.37938579  69.74446818  63.33212383 101.84236874  40.90414173\n",
      " 101.84236874  71.19282736  77.86535685  26.60176494   1.66029461\n",
      " 119.75737424  38.58150596  81.07211401  65.78091795  74.34722903\n",
      "  66.80971869  99.71307187  79.38971689   1.43645302  66.95862138\n",
      "  80.53560926  49.18123427  77.31152515 115.54182358  32.12437716\n",
      "  23.75378742  71.47486948  77.60290089  72.7176641   82.77033889\n",
      "  99.40116797 260.84035991  78.16020183  78.5544281   68.71041375\n",
      "  70.04864743   1.66029461  70.12687192  11.04635432  75.6093501\n",
      "  44.54211778   1.66029461  57.99479595  53.92309526   2.87267472\n",
      " 100.63074933  83.9877304   24.17737575  25.02707329  79.95770611\n",
      "  57.83671197 115.3041336   50.88620643 134.73903212  75.78310256\n",
      "  32.39300414]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "model_score = model.score(x_train, y_train)\n",
    "\n",
    "print('R2 sq: ', model_score)\n",
    "\n",
    "y_predicted = model.predict(x_test)\n",
    "#print(y_test)\n",
    "#print(y_predicted)\n",
    "#mean squared error\n",
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_predicted))\n",
    "\n",
    "#explained variance score: 1 is perfect prediction\n",
    "print('Test Variance score: %.2f' % r2_score(y_test, y_predicted))\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('predicted')\n",
    "ax.set_title(\"GT vs Perdict\")\n",
    "plt.show()\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-b56c2ea4345d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R2 sq: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;31m# XXX: Remove the check in 0.23\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2528\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \"\"\"\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0;31m# In regression we can directly return the raw value from the trees.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "x = Bowler_train.iloc[:,3:-1]\n",
    "y = Bowler_train.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state=42, shuffle=True)\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "\t  'learning_rate': 0.01, 'loss': 'ls'}\n",
    "\n",
    "model = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "try:\n",
    "    model.fit(x_train, y_train)\n",
    "except ValueError:\n",
    "    print('Error occurred')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "model_score = model.score(x_train, y_train)\n",
    "\n",
    "print('R2 sq: ', model_score)\n",
    "\n",
    "y_predicted = model.predict(x_test)\n",
    "#print(y_test)\n",
    "#print(y_predicted)\n",
    "#mean squared error\n",
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_predicted))\n",
    "\n",
    "#explained variance score: 1 is perfect prediction\n",
    "print('Test Variance score: %.2f' % r2_score(y_test, y_predicted))\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('predicted')\n",
    "ax.set_title(\"GT vs Perdict\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the team1 name : England\n",
      "Enter the team2 name : Sri Lanka\n",
      "Enter the venue : Headingley\n",
      "Plz enter the players playing today for  England\n",
      "Enter player : ME Trescothick\n",
      "Enter player : AN Cook\n",
      "Enter player : IR Bell\n",
      "Enter player : AJ Strauss\n",
      "Enter player : VS Solanki\n",
      "Enter player : JWM Dalrymple\n",
      "Enter player : GO Jones\n",
      "Enter player : TT Bresnan\n",
      "Enter player : LE Plunkett\n",
      "Enter player : \n",
      "Enter player : Kabir Ali\n",
      "Plz enter the players playing today for  Sri Lanka\n",
      "Enter player : SL Malinga\n",
      "Enter player : MF Maharoof\n",
      "Enter player : ST Jayasuriya\n",
      "Enter player : CRD Fernando\n",
      "Enter player : WU Tharanga\n",
      "Enter player : DPMD Jayawardene\n",
      "Enter player : KC Sangakkara\n",
      "Enter player : WPUJC Vaas\n",
      "Enter player : TM Dilshan\n",
      "Enter player : HMCM Bandara\n",
      "Enter player : \n"
     ]
    }
   ],
   "source": [
    "def input_call():\n",
    "    f = open('./input_data_1.csv','w')\n",
    "    writer = csv.DictWriter(f,fieldnames=['NAME','OPPONENT','VENUE'])\n",
    "    writer.writeheader()\n",
    "    f.close()\n",
    "    input_list_team1=[]\n",
    "    input_list_team2=[]\n",
    "    input_list=[]\n",
    "    in_team1=input(\"Enter the team1 name : \")\n",
    "    in_team2=input(\"Enter the team2 name : \")\n",
    "    in_venue=input(\"Enter the venue : \")\n",
    "    print(\"Plz enter the players playing today for \", in_team1)\n",
    "    for i in range(11):\n",
    "        temp=input(\"Enter player : \")\n",
    "        input_list.append(temp)\n",
    "        input_list_team1.append(temp)\n",
    "        input_fields=pd.DataFrame({'NAME':[temp] ,'OPPONENT':[in_team2],'VENUE':[in_venue]})\n",
    "        with open('./input_data_1.csv','a') as bd:\n",
    "            input_fields.to_csv(bd,header=False,index=False)\n",
    "    print(\"Plz enter the players playing today for \", in_team2)\n",
    "    for i in range(11):\n",
    "        temp=input(\"Enter player : \")\n",
    "        input_list.append(temp)\n",
    "        input_list_team2.append(temp)    \n",
    "        input_fields=pd.DataFrame({'NAME':[temp] ,'OPPONENT':[in_team1],'VENUE':[in_venue]})\n",
    "        with open('./input_data_1.csv','a') as bd:\n",
    "            input_fields.to_csv(bd,header=False,index=False)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "input_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tot_wkts</th>\n",
       "      <th>Tot_SR</th>\n",
       "      <th>Tot_avg</th>\n",
       "      <th>Opp_wkts</th>\n",
       "      <th>Opp_SR</th>\n",
       "      <th>Opp_avg</th>\n",
       "      <th>Ven_wkts</th>\n",
       "      <th>Ven_SR</th>\n",
       "      <th>Ven_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>677</td>\n",
       "      <td>12</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>35.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>177</td>\n",
       "      <td>33.689266</td>\n",
       "      <td>22.440678</td>\n",
       "      <td>12</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>3</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>693</td>\n",
       "      <td>3</td>\n",
       "      <td>56.333333</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>6</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>7</td>\n",
       "      <td>28.857143</td>\n",
       "      <td>29.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>693 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tot_wkts     Tot_SR    Tot_avg  Opp_wkts     Opp_SR    Opp_avg  Ven_wkts  \\\n",
       "677        12  41.333333  35.583333         0   0.000000   0.000000         0   \n",
       "521         1  48.000000  44.000000         0   0.000000   0.000000         0   \n",
       "741       177  33.689266  22.440678        12  36.666667  22.000000         1   \n",
       "363         3  40.666667  43.000000         0        inf        inf         0   \n",
       "693         3  56.333333  46.666667         0   0.000000   0.000000         0   \n",
       "..        ...        ...        ...       ...        ...        ...       ...   \n",
       "106         1  81.000000  65.000000         0   0.000000   0.000000         0   \n",
       "270         0        inf        inf         0   0.000000   0.000000         0   \n",
       "860         6  21.333333  15.000000         3  22.666667  13.666667         0   \n",
       "435         7  28.857143  29.571429         0   0.000000   0.000000         0   \n",
       "102         3  31.666667  24.333333         0   0.000000   0.000000         0   \n",
       "\n",
       "     Ven_SR  Ven_avg  \n",
       "677     0.0      0.0  \n",
       "521     0.0      0.0  \n",
       "741    43.0     32.0  \n",
       "363     0.0      0.0  \n",
       "693     0.0      0.0  \n",
       "..      ...      ...  \n",
       "106     inf      inf  \n",
       "270     0.0      0.0  \n",
       "860     0.0      0.0  \n",
       "435     0.0      0.0  \n",
       "102     0.0      0.0  \n",
       "\n",
       "[693 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Tot_runs</th>\n",
       "      <th>Tot_SR</th>\n",
       "      <th>Tot_avg</th>\n",
       "      <th>Opp_runs</th>\n",
       "      <th>Opp_SR</th>\n",
       "      <th>Opp_avg</th>\n",
       "      <th>Ven_runs</th>\n",
       "      <th>Ven_SR</th>\n",
       "      <th>Ven_avg</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A Bagai</td>\n",
       "      <td>Maple Leaf North-West Ground</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>558</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A Balbirnie</td>\n",
       "      <td>|||||||Civil Service Cricket Club|||</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>839</td>\n",
       "      <td>0.723900</td>\n",
       "      <td>25.424242</td>\n",
       "      <td>253</td>\n",
       "      <td>0.829508</td>\n",
       "      <td>36.142857</td>\n",
       "      <td>26</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A Codrington</td>\n",
       "      <td>Jaffery Sports Club Ground</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A Dananjaya</td>\n",
       "      <td>|||||||R.Premadasa Stadium|||</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A Flintoff</td>\n",
       "      <td>|||||||Beausejour Stadium|||</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>781</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>22.314286</td>\n",
       "      <td>43</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>Zeeshan Maqsood</td>\n",
       "      <td>Mannofield Park</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>26</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1126</td>\n",
       "      <td>Zeeshan Siddiqi</td>\n",
       "      <td>Hagley Oval</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1127</td>\n",
       "      <td>Ziaur Rahman</td>\n",
       "      <td>Shere Bangla National Stadium</td>\n",
       "      <td>India</td>\n",
       "      <td>124</td>\n",
       "      <td>1.097345</td>\n",
       "      <td>11.272727</td>\n",
       "      <td>20</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>14</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1128</td>\n",
       "      <td>Zulfiqar Babar</td>\n",
       "      <td>Shere Bangla National Stadium</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>35</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1129</td>\n",
       "      <td>Zulqarnain Haider</td>\n",
       "      <td>Dubai International Cricket Stadium</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>48</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1130 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 player                                 Venue  \\\n",
       "0               A Bagai          Maple Leaf North-West Ground   \n",
       "1           A Balbirnie  |||||||Civil Service Cricket Club|||   \n",
       "2          A Codrington            Jaffery Sports Club Ground   \n",
       "3           A Dananjaya         |||||||R.Premadasa Stadium|||   \n",
       "4            A Flintoff          |||||||Beausejour Stadium|||   \n",
       "...                 ...                                   ...   \n",
       "1125    Zeeshan Maqsood                       Mannofield Park   \n",
       "1126    Zeeshan Siddiqi                           Hagley Oval   \n",
       "1127       Ziaur Rahman         Shere Bangla National Stadium   \n",
       "1128     Zulfiqar Babar         Shere Bangla National Stadium   \n",
       "1129  Zulqarnain Haider   Dubai International Cricket Stadium   \n",
       "\n",
       "              Opponent  Tot_runs    Tot_SR    Tot_avg  Opp_runs    Opp_SR  \\\n",
       "0          Netherlands       558  0.632653  31.000000        26  0.382353   \n",
       "1             Zimbabwe       839  0.723900  25.424242       253  0.829508   \n",
       "2                Kenya         5  0.714286   5.000000         5  0.714286   \n",
       "3           Bangladesh         7  0.333333   3.500000         0  0.000000   \n",
       "4          West Indies       781  0.855422  22.314286        43  0.716667   \n",
       "...                ...       ...       ...        ...       ...       ...   \n",
       "1125  Papua New Guinea        26  0.490566   6.500000        25  0.609756   \n",
       "1126          Scotland         7  0.333333   7.000000         7  0.333333   \n",
       "1127             India       124  1.097345  11.272727        20  1.176471   \n",
       "1128        Bangladesh        35  0.875000   7.000000         1  0.250000   \n",
       "1129      South Africa        48  0.685714  12.000000        48  0.685714   \n",
       "\n",
       "        Opp_avg  Ven_runs    Ven_SR    Ven_avg  Performance  \n",
       "0     13.000000         8  0.222222   4.000000           17  \n",
       "1     36.142857        26  0.666667   8.666667           55  \n",
       "2      5.000000         5  0.714286   5.000000           71  \n",
       "3      0.000000         0  0.000000   0.000000            0  \n",
       "4     10.750000         3  0.428571   1.500000           50  \n",
       "...         ...       ...       ...        ...          ...  \n",
       "1125  12.500000        26  0.490566   6.500000           50  \n",
       "1126   7.000000         7  0.333333   7.000000           33  \n",
       "1127   6.666667        14  0.736842   4.666667            0  \n",
       "1128   1.000000         1  0.250000   1.000000           25  \n",
       "1129  12.000000        30  0.937500  15.000000           82  \n",
       "\n",
       "[1130 rows x 13 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = pd.read_csv('input_data_1.csv', header = 0)\n",
    "data_ref=pd.read_csv('Bat_Trainset.csv',header =0)\n",
    "data_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=int(Input['NAME'].count())\n",
    "cnt=[]\n",
    "for i in range (a):\n",
    "    temp = data_ref[data_ref.player == Input['NAME'][i]]\n",
    "    temp = temp[temp.Opponent == Input['OPPONENT'][i]]\n",
    "    temp = temp[temp.Venue == Input['VENUE'][i]]\n",
    "    if (temp.empty == False ):\n",
    "            temp=temp.drop(['player','Venue','Opponent'],axis = 1)\n",
    "            cnt.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cnt[0].iloc[:, :-1]\n",
    "Y = cnt[0].iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122.10031055])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(X)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1082    125\n",
       "Name: Performance, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      Tot_runs    Tot_SR  Tot_avg  Opp_runs    Opp_SR  Opp_avg  Ven_runs  \\\n",
       " 1082        71  0.865854    17.75        54  1.018868     27.0        44   \n",
       " \n",
       "         Ven_SR  Ven_avg  Performance  \n",
       " 1082  1.257143     44.0          125  ,\n",
       "      Tot_runs    Tot_SR    Tot_avg  Opp_runs    Opp_SR  Opp_avg  Ven_runs  \\\n",
       " 346       181  0.891626  20.111111        74  1.042254     14.8         2   \n",
       " \n",
       "      Ven_SR  Ven_avg  Performance  \n",
       " 346     0.4      2.0           40  ]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
